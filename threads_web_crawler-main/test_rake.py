from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from time import sleep
from bs4 import BeautifulSoup
import jieba
from rake_nltk import Rake
import nltk
import pickle

# ä¸‹è¼‰ Rake æ‰€éœ€è³‡æº
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('punkt_tab')

# å®‰è£ä¸¦å•Ÿå‹• ChromeDriver
service = Service(ChromeDriverManager().install())
driver = webdriver.Chrome(service=service)

# ä½¿ç”¨ Selenium å…§å»ºçš„æ–¹å¼ä¾†è‡ªå‹•åµæ¸¬ ChromeDriver
driver = webdriver.Chrome()

# é–‹å•Ÿ Threads ç¶²ç«™
driver.get('https://www.threads.net/?hl=zh-tw')           
sleep(3)

# æ¨¡æ“¬æ»¾å‹•é é¢ï¼Œä½¿æ›´å¤šå…§å®¹è¼‰å…¥
for i in range(5):
    n = f'window.scrollTo(0, {200 + i * 2000})'
    driver.execute_script(n)
    sleep(1)

# å–å¾— HTML å…§å®¹ä¸¦è§£æ
html_content = driver.page_source
soup = BeautifulSoup(html_content, "html.parser")

# æ‰¾å‡ºç‰¹å®šçš„ HTML å…ƒç´ 
target_element = soup.select_one(".x78zum5.xdt5ytf.x1iyjqo2.x1n2onr6")

# é€™å€‹ class å¯èƒ½éœ€è¦ä¾æ“š Threads ç¶²ç«™çš„è®Šæ›´ä¾†èª¿æ•´
# æå–ç‰¹å®š class çš„å…§å®¹
try:
    target_element = soup.select_one(".x78zum5.xdt5ytf.x1iyjqo2.x1n2onr6")
    if target_element:
        classes = target_element.find_all(class_=[
            "x1a6qonq x6ikm8r x10wlt62 xj0a0fe x126k92a x6prxxf x7r5mf7",
            "xu9jpxn x1n2onr6 xqcsobp x12w9bfk x1wsgiic xuxw1ft x1bl4301"
        ])
    else:
        classes = []  # å¦‚æœæ‰¾ä¸åˆ°ç›®æ¨™å…ƒç´ ï¼Œå›å‚³ç©ºåˆ—è¡¨
except Exception as e:
    print("ç™¼ç”ŸéŒ¯èª¤ï¼Œç„¡æ³•è§£æ HTMLï¼š", e)
    classes = []

# å„²å­˜çˆ¬å–åˆ°çš„æ–‡ç« å…§å®¹
post = [i.get_text(strip=True) for i in classes]

# å°å‡ºæ‰€æœ‰çˆ¬å–åˆ°çš„æ–‡ç« 
for i, text in enumerate(post):
    print(f"No.{i} : {text[:30]}...")

# è®“ä½¿ç”¨è€…é¸æ“‡è¦æŸ¥çœ‹çš„æ–‡ç« å…§å®¹
input("âœ… æŒ‰ä¸‹ Enter éµé–‹å§‹ rake åˆ†æ")

# åˆå§‹åŒ– RAKE
rake = Rake()
corpus_rake = []

for idx, text in enumerate(post):
    words = list(jieba.cut(text))
    joined_text = ' '.join(words)
    rake.extract_keywords_from_text(joined_text)
    keywords = [kw for score, kw in rake.get_ranked_phrases_with_scores()[:5]]  # æœ€å¤šå–å‰5å€‹
    corpus_rake.append(keywords)
    # print(f"ç¬¬ {idx+1} ç¯‡å®Œæˆ âœ…")
    print(f"ğŸ‘‰ ç¬¬ {idx+1} ç¯‡æ–‡ç« çš„å‰äº”åé—œéµå­—ï¼š")
    for keyword in keywords:
        print(f"   - {keyword}")
    print("-" * 40)


# å­˜æˆ pkl
with open("corpus_rake.pkl", "wb") as f:
    pickle.dump(corpus_rake, f)

# é—œé–‰ç€è¦½å™¨
input("\nâœ… å·²å„²å­˜ rake é—œéµè©è‡³ corpus_rake.pkl")
driver.quit()