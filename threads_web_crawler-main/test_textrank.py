import jieba
import jieba.analyse
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from time import sleep
from bs4 import BeautifulSoup
import pickle

# å®‰è£ä¸¦å•Ÿå‹• ChromeDriver
service = Service(ChromeDriverManager().install())
driver = webdriver.Chrome(service=service)

# é–‹å•Ÿ Threads ç¶²ç«™
driver.get('https://www.threads.net/?hl=zh-tw')
sleep(3)

# æ¨¡æ“¬æ»¾å‹•é é¢
for i in range(5):
    driver.execute_script(f'window.scrollTo(0, {200 + i * 2000})')
    sleep(1)

# è§£æ HTML
soup = BeautifulSoup(driver.page_source, "html.parser")

# å˜—è©¦æ‰¾å‡º Threads æ–‡ç« çš„å€å¡Š
try:
    target_element = soup.select_one(".x78zum5.xdt5ytf.x1iyjqo2.x1n2onr6")
    if target_element:
        classes = target_element.find_all(class_=[
            "x1a6qonq x6ikm8r x10wlt62 xj0a0fe x126k92a x6prxxf x7r5mf7",
            "xu9jpxn x1n2onr6 xqcsobp x12w9bfk x1wsgiic xuxw1ft x1bl4301"
        ])
    else:
        classes = []
except Exception as e:
    print("ç™¼ç”ŸéŒ¯èª¤ï¼Œç„¡æ³•è§£æ HTMLï¼š", e)
    classes = []

# å„²å­˜çˆ¬å–åˆ°çš„æ–‡ç« å…§å®¹
post = []
for i in classes:
    # ç§»é™¤å­å…ƒç´ ä¸­å«åšã€Œç¿»è­¯ã€çš„å…§å®¹
    for unwanted in i.find_all(string="ç¿»è­¯"):
        unwanted.extract()
    text = i.get_text(strip=True)
    if text:
        post.append(text)

# é¡¯ç¤ºæ‰€æœ‰æ–‡ç« 
for i, content in enumerate(post):
    print(f"No. {i+1}: {content}")

input("âœ… æŒ‰ä¸‹ Enter éµé–‹å§‹ textrank åˆ†æ")

# å„²å­˜æ¯ç¯‡æ–‡ç« çš„å‰ 5 å€‹é—œéµè©ï¼ˆåªæœ‰è©ï¼Œä¸è¦åˆ†æ•¸ï¼‰
corpus_textrank = []
# â¤ ä½¿ç”¨ TextRank æå–é—œéµå­—
for i, text in enumerate(post):
    keywords = jieba.analyse.textrank(text, topK=5, withWeight=True)
    print(f"\nğŸ” æ–‡ç«  {i+1} çš„é—œéµå­—æ’åï¼ˆTextRank Top 5ï¼‰ï¼š")
    keywords_only = []
    for word, weight in keywords:
        print(f"{word} ({weight:.4f})")
        keywords_only.append(word)
    corpus_textrank.append(keywords_only)

# å„²å­˜æˆ pkl
with open("corpus_textrank.pkl", "wb") as f:
    pickle.dump(corpus_textrank, f)
    
input("\nâœ… å·²å„²å­˜ textrank é—œéµè©è‡³ corpus_textrank.pkl")
driver.quit()